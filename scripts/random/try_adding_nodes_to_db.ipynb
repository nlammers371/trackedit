{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultrack.core.database import NodeDB, get_node_values\n",
    "from ultrack.core.interactive import add_new_node\n",
    "from ultrack.config import MainConfig\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine, inspect, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = Path('/home/teun.huijben/Documents/data/Akila/20241003/neuromast4_t851/adjusted/')\n",
    "db_filename_new = 'data_v1.db'\n",
    "\n",
    "config_adjusted = MainConfig()\n",
    "config_adjusted.data_config.working_dir = working_directory\n",
    "config_adjusted.data_config.database_file_name = db_filename_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 175000014\n",
    "field = NodeDB.pickle\n",
    "\n",
    "index = [int(index)]\n",
    "\n",
    "val = get_node_values(config_adjusted.data_config,\n",
    "        indices=index,\n",
    "        values=field)\n",
    "\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columns 1by1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(config_adjusted.data_config.database_path)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "columns_info = inspector.get_columns('nodes')\n",
    "column_names = [col['name'] for col in columns_info]\n",
    "\n",
    "print(column_names)\n",
    "print(len(column_names))\n",
    "\n",
    "# print(' ')\n",
    "# for i,c in enumerate(column_names):\n",
    "#     offset = 79\n",
    "#     if i >=3:\n",
    "#         offset += 1\n",
    "#     print(i+offset,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add missing columns 1 by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = {\n",
    "    'frontier': 'FLOAT DEFAULT -1.0',\n",
    "    'height': 'FLOAT DEFAULT -1.0',\n",
    "    'features': 'FLOAT DEFAULT -1.0',\n",
    "    'node_prob': 'FLOAT DEFAULT -1.0',\n",
    "}\n",
    "\n",
    "engine = create_engine(config_adjusted.data_config.database_path)\n",
    "inspector = inspect(engine)\n",
    "existing_columns = [col['name'] for col in inspector.get_columns('nodes')]\n",
    "\n",
    "for col_name, col_definition in expected_columns.items():\n",
    "    if col_name not in existing_columns:\n",
    "        alter_stmt = f\"ALTER TABLE nodes ADD COLUMN {col_name} {col_definition};\"\n",
    "        with engine.begin() as conn:  # This starts a transaction.\n",
    "            conn.execute(text(alter_stmt))\n",
    "        print(f\"Added missing column: {col_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check frontier value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = 175000014\n",
    "fr = get_node_values(config_adjusted.data_config, [int(node_id)], NodeDB.frontier)\n",
    "print(fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all missing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected columns {'t': 'INTEGER', 'id': 'BIGINT', 'parent_id': 'BIGINT DEFAULT -1', 'hier_parent_id': 'BIGINT DEFAULT -1', 't_node_id': 'INTEGER', 't_hier_id': 'INTEGER', 'z': 'FLOAT', 'y': 'FLOAT', 'x': 'FLOAT', 'z_shift': 'FLOAT DEFAULT 0.0', 'y_shift': 'FLOAT DEFAULT 0.0', 'x_shift': 'FLOAT DEFAULT 0.0', 'area': 'INTEGER', 'frontier': 'FLOAT DEFAULT -1.0', 'height': 'FLOAT DEFAULT -1.0', 'selected': 'BOOLEAN DEFAULT False', 'pickle': 'BLOB', 'features': 'BLOB', 'node_prob': 'FLOAT DEFAULT -1.0', 'segm_annot': 'VARCHAR(14) DEFAULT 0', 'node_annot': 'VARCHAR(7) DEFAULT 0', 'appear_annot': 'VARCHAR(7) DEFAULT 0', 'disappear_annot': 'VARCHAR(7) DEFAULT 0', 'division_annot': 'VARCHAR(7) DEFAULT 0'}\n",
      "Added missing column: frontier\n",
      "Added missing column: height\n",
      "Added missing column: features\n",
      "Added missing column: node_prob\n"
     ]
    }
   ],
   "source": [
    "def get_expected_columns(nodedb, engine):\n",
    "    expected_columns = {}\n",
    "    for column in nodedb.__table__.columns:\n",
    "        # Compile the column type to its SQL representation.\n",
    "        col_type_str = column.type.compile(dialect=engine.dialect)\n",
    "        \n",
    "        # Try to extract a default value if one is specified.\n",
    "        default_value = None\n",
    "        if column.default is not None and hasattr(column.default, \"arg\"):\n",
    "            default_value = column.default.arg\n",
    "\n",
    "        # Build the definition string.\n",
    "        col_definition = col_type_str\n",
    "        if default_value is not None:\n",
    "            col_definition += f\" DEFAULT {default_value}\"\n",
    "        \n",
    "        expected_columns[column.name] = col_definition\n",
    "    return expected_columns\n",
    "\n",
    "engine = create_engine(config_adjusted.data_config.database_path)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "expected_columns = get_expected_columns(NodeDB, engine)\n",
    "existing_columns = [col['name'] for col in inspector.get_columns('nodes')]\n",
    "print('expected columns',expected_columns)\n",
    "\n",
    "for col_name, col_definition in expected_columns.items():\n",
    "    if col_name not in existing_columns:\n",
    "        alter_stmt = f\"ALTER TABLE nodes ADD COLUMN {col_name} {col_definition};\"\n",
    "        with engine.begin() as conn:  # This starts a transaction.\n",
    "            conn.execute(text(alter_stmt))\n",
    "        print(f\"Added missing column: {col_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 114946\n",
      "bbox: [ 20 645 200  56 714 372]\n",
      "area: 51215.0\n",
      "centroid: [ 39 679 296]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "node_id = 175000014\n",
    "time = 176\n",
    "\n",
    "pickle = get_node_values(config_adjusted.data_config, [int(node_id)], NodeDB.pickle)\n",
    "print(pickle)\n",
    "\n",
    "new_id = add_new_node(config_adjusted,\n",
    "                        time = time,\n",
    "                        mask = pickle.mask,\n",
    "                        bbox = pickle.bbox,\n",
    "                        include_overlaps=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51215\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "from ultrack.core.segmentation.node import Node\n",
    "\n",
    "node = Node.from_mask(\n",
    "        time=time,\n",
    "        mask=pickle.mask,\n",
    "        bbox=np.asarray(pickle.bbox),\n",
    "    )\n",
    "\n",
    "print(node.area)\n",
    "print(type(node.area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
